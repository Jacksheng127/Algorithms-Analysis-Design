{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Aspect** | Weighted Scoring | Decision Tree | Utility Theory |\n",
    "| -------|------------------|---------------|----------------|\n",
    "| **Intro** | Involves defining a set of criteria relevant to the decision or evaluation, assigning weights to each criterion based on its relative importance, and scoring each alternative against each criterion. The scores are then multiplied by the respective weights and aggregated to obtain a final weighted score for each alternative. The alternative with the highest weighted score is often considered the most favorable choice. | The Decision Tree algorithm recursively partitions the dataset based on the most informative features, creating a hierarchical tree structure of decision rules. Starting with the entire dataset, it selects the best feature to split the data, creating subsets. This process continues until a stopping criterion is met. The algorithm assigns class or outcome labels to the leaf nodes based on the majority class or average value. The resulting tree can be used for prediction by following the decision path from the root to a leaf node. Overall, Decision Trees provide an interpretable and intuitive approach for classification and regression tasks. | Involves defining a set of potential outcomes for each decision alternative and assigning a utility value to each outcome that reflects the decision-maker's satisfaction or preference for that outcome. Utility values typically range to represent preferences, with higher values indicating more preferred outcomes. Probabilities are then estimated for each outcome occurring under each alternative. The utility of each outcome is multiplied by its probability, and these products are summed to calculate the expected utility for each decision alternative. The alternative with the highest expected utility is considered the most favorable choice as it represents the highest average level of satisfaction or value, accounting for all possible outcomes and their likelihoods. |\n",
    "| **Approach** | This approach involves assigning weights to various factors (such as safety from wild animals and ease of access due to land conditions) and scoring each island based on these weights. The island with the highest score would be deemed the safest and most promising for exploration. | A decision tree algorithm would involve creating a model that uses the features of each island (such as land condition and presence of wild animals) as inputs and provides a decision output on whether or not to search that island. The decision at each node in the tree is based on the safest and most promising characteristics derived from the data provided. |  Utility theory involves defining a utility function (using Utility value with respective probability) that quantifies the satisfaction or value derived from choosing a particular island, considering various attributes of each island. The choice with the highest expected utility is selected. |\n",
    "| **Time Complexity** | Best: O(n), where n is the number of islands. <br> Average: O(n) <br> Worst: O(n)| Training: <br> Best: O(n log(n)), where ùëõ n is the number of training samples <br> Average: O(n * m * log(n)), where ùëö m is the number of features <br> Worst: O(n^2 * m) <br><br>Prediction: <br> O(h), where ‚Ñé h is the height of the tree. In a well-balanced tree, h would approximately be log(n) | Best: O(n), where n is the number of islands. <br> Average: O(n) <br> Worst: O(n) |\n",
    "| **Advantages** | Flexibility: Can easily adjust weights and add or remove criteria based on new information or priorities. <br><br> Simplicity: This method is straightforward and quick, making it suitable for situations where criteria and their respective weights are clearly defined. <br><br> It requires minimal computational resources. <br><br> Speed: Faster computational times due to simpler arithmetic. <br><br> Transparency: Results are easy to interpret and explain. | Complex Decision Boundaries: Decision trees can handle complex, non-linear decision boundaries. For Algo Jones, this means the model can accommodate complex interactions between various features of each island, such as the combination of terrain types and animal dangers, without requiring explicit modeling of these interactions. <br><br> Multi-Feature Splitting: Decision trees can evaluate multiple features simultaneously. Algo Jones can factor in various attributes of the islands (e.g., land condition, wild animal presence) and the decision tree can use these multiple factors to determine the optimal search area. <br><br> Flexible Data Integration: Trees naturally integrate both numerical data (like the size of an island or the number of wild animal sightings) and categorical data (such as type of terrain or presence/absence of certain features). This flexibility is valuable in environments with diverse data types. | Systematic Approach: Utility Theory provides a structured framework to make decisions under uncertainty. It systematically incorporates the probabilities of various outcomes and their respective utilities, leading to decisions that maximize expected utility based on given information. <br><br> Personalized Decision Framework: Utility Theory allows Algo Jones to incorporate his personal risk aversion or appetite into the decision-making process. This means that the theory can adapt whether he is risk-averse, risk-neutral, or risk-seeking, by adjusting how utility values are assigned to outcomes. <br><br> Complex Outcome Management: Utility Theory is particularly effective in situations where there are multiple potential outcomes with varying probabilities. It can take into account not just the positive outcomes (e.g., finding the statue) but also negative possibilities (e.g., encountering dangerous wildlife) and neutral outcomes (e.g., an uneventful search). |\n",
    "| **Disadvantages** | Still Subjective: Like MCDA, the outcomes can be heavily influenced by the choice of weights and scores.  <br><br> Potential for Oversimplification: Might not capture the full complexity of a decision if important criteria are overlooked or insufficiently weighted.  <br><br> Less Nuanced: Might not capture the complexities where interactions between criteria are non-linear or where qualitative judgment is significant. | Complexity: The construction of decision trees can be complex, especially if there are many criteria and possible outcomes. They require more computational effort and understanding of the decision structure than linear methods like scoring. <br><br>  Overfitting: overfitting with limited data which might not generalize well to changes in the problem or environment. <br><br>  Requires a good amount of data to train effectively, which may not be available here (only 5 islands). <br><br> Can be biased toward attributes with more categories and may overfit. | Harder to Quantify: Preferences and utilities may be difficult to quantify accurately, especially in subjective or nuanced scenarios. <br><br>  Complexity in Application: Defining utility functions and estimating probabilities can be complex and require a lot of information. <br><br>  Subjectivity: Defining utility functions and estimating probabilities can be highly subjective and challenging. <br><br>  Dependence on Reliable Data: The effectiveness of the utility theory approach hinges on the accuracy of the probability estimates and utility values. |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../OS algorithms test/time complexity - graph.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "islands = {\n",
    "    'North': {'land_condition_risk': 4, 'wild_animal_risk': 5},\n",
    "    'South': {'land_condition_risk': 3, 'wild_animal_risk': 3},\n",
    "    'East': {'land_condition_risk': 2, 'wild_animal_risk': 5},\n",
    "    'West': {'land_condition_risk': 1, 'wild_animal_risk': 2},\n",
    "    'Middle': {'land_condition_risk': 2, 'wild_animal_risk': 1}\n",
    "}\n",
    "\n",
    "def weighted_scoring(islands):\n",
    "    # Weights: Higher means the criterion is more important\n",
    "    weights = {'wild_animal_risk': 0.7, 'land_condition_risk': 0.3}\n",
    "\n",
    "    scores = {}\n",
    "    for island, attributes in islands.items():\n",
    "        score = (attributes['wild_animal_risk'] * weights['wild_animal_risk'] +\n",
    "                 attributes['land_condition_risk'] * weights['land_condition_risk'])\n",
    "        scores[island] = score\n",
    "    \n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'North': 4.7, 'South': 2.9999999999999996, 'East': 4.1, 'West': 1.7, 'Middle': 1.2999999999999998}\n",
      "+--------------------+---------+\n",
      "| Island Direction   |   Score |\n",
      "+====================+=========+\n",
      "| North              |     4.7 |\n",
      "+--------------------+---------+\n",
      "| South              |     3   |\n",
      "+--------------------+---------+\n",
      "| East               |     4.1 |\n",
      "+--------------------+---------+\n",
      "| West               |     1.7 |\n",
      "+--------------------+---------+\n",
      "| Middle             |     1.3 |\n",
      "+--------------------+---------+\n",
      "Best island to search according to Weighted Scoring: Middle\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "scores = weighted_scoring(islands)\n",
    "print(scores)\n",
    "islandInfo = [[key, value] for key, value in scores.items()]\n",
    "headers = [\"Island Direction\"] + [\"Score\"]\n",
    "print(tabulate(islandInfo, headers=headers, tablefmt='grid'))\n",
    "\n",
    "best_island = min(scores, key=scores.get)\n",
    "print(f\"Best island to search according to Weighted Scoring: {best_island}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
